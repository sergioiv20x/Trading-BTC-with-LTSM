{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on the code of Samantha Molnar found on\n",
    "#http://samanthamolnar.me/personal/2017/05/02/hacking-google-trends.html\n",
    "\n",
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "keyword_list = [\"bitcoin\"] # term to search in googletrends\n",
    "dates0=pd.read_excel(\"dates0.xlsx\") #this file contains the list of weeks to be requested to google\n",
    "#as google raises error code 500 after 100 requests, there is another file \"dates1.xlsx\" with the last weeks\n",
    "dates1=pd.read_excel(\"dates1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weeks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-18 2019-05-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-25 2019-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-01 2019-06-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-08 2019-06-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-15 2019-06-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Weeks\n",
       "0  2019-05-18 2019-05-25\n",
       "1  2019-05-25 2019-06-01\n",
       "2  2019-06-01 2019-06-08\n",
       "3  2019-06-08 2019-06-15\n",
       "4  2019-06-15 2019-06-21"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obtained google trends for the period 2017-07-01T00 2017-07-08T00\n",
      "obtained google trends for the period 2017-07-08T00 2017-07-15T00\n",
      "obtained google trends for the period 2017-07-15T00 2017-07-22T00\n",
      "obtained google trends for the period 2017-07-22T00 2017-07-29T00\n",
      "obtained google trends for the period 2017-07-29T00 2017-08-05T00\n",
      "obtained google trends for the period 2017-08-05T00 2017-08-12T00\n",
      "obtained google trends for the period 2017-08-12T00 2017-08-19T00\n",
      "obtained google trends for the period 2017-08-19T00 2017-08-26T00\n",
      "obtained google trends for the period 2017-08-26T00 2017-09-02T00\n",
      "obtained google trends for the period 2017-09-02T00 2017-09-09T00\n",
      "obtained google trends for the period 2017-09-09T00 2017-09-16T00\n",
      "obtained google trends for the period 2017-09-16T00 2017-09-23T00\n",
      "obtained google trends for the period 2017-09-23T00 2017-09-30T00\n",
      "obtained google trends for the period 2017-09-30T00 2017-10-07T00\n",
      "obtained google trends for the period 2017-10-07T00 2017-10-14T00\n",
      "obtained google trends for the period 2017-10-14T00 2017-10-21T00\n",
      "obtained google trends for the period 2017-10-21T00 2017-10-28T00\n",
      "obtained google trends for the period 2017-10-28T00 2017-11-04T00\n",
      "obtained google trends for the period 2017-11-04T00 2017-11-11T00\n",
      "obtained google trends for the period 2017-11-11T00 2017-11-18T00\n",
      "obtained google trends for the period 2017-11-18T00 2017-11-25T00\n",
      "obtained google trends for the period 2017-11-25T00 2017-12-02T00\n",
      "obtained google trends for the period 2017-12-02T00 2017-12-09T00\n",
      "obtained google trends for the period 2017-12-09T00 2017-12-16T00\n",
      "obtained google trends for the period 2017-12-16T00 2017-12-23T00\n",
      "obtained google trends for the period 2017-12-23T00 2017-12-30T00\n",
      "obtained google trends for the period 2017-12-30T00 2018-01-06T00\n",
      "obtained google trends for the period 2018-01-06T00 2018-01-13T00\n",
      "obtained google trends for the period 2018-01-13T00 2018-01-20T00\n",
      "obtained google trends for the period 2018-01-20T00 2018-01-27T00\n",
      "obtained google trends for the period 2018-01-27T00 2018-02-03T00\n",
      "obtained google trends for the period 2018-02-03T00 2018-02-10T00\n",
      "obtained google trends for the period 2018-02-10T00 2018-02-17T00\n",
      "obtained google trends for the period 2018-02-17T00 2018-02-24T00\n",
      "obtained google trends for the period 2018-02-24T00 2018-03-03T00\n",
      "obtained google trends for the period 2018-03-03T00 2018-03-10T00\n",
      "obtained google trends for the period 2018-03-10T00 2018-03-17T00\n",
      "obtained google trends for the period 2018-03-17T00 2018-03-24T00\n",
      "obtained google trends for the period 2018-03-24T00 2018-03-31T00\n",
      "obtained google trends for the period 2018-03-31T00 2018-04-07T00\n",
      "obtained google trends for the period 2018-04-07T00 2018-04-14T00\n",
      "obtained google trends for the period 2018-04-14T00 2018-04-21T00\n",
      "obtained google trends for the period 2018-04-21T00 2018-04-28T00\n",
      "obtained google trends for the period 2018-04-28T00 2018-05-05T00\n",
      "obtained google trends for the period 2018-05-05T00 2018-05-12T00\n",
      "obtained google trends for the period 2018-05-12T00 2018-05-19T00\n",
      "obtained google trends for the period 2018-05-19T00 2018-05-26T00\n",
      "obtained google trends for the period 2018-05-26T00 2018-06-02T00\n",
      "obtained google trends for the period 2018-06-02T00 2018-06-09T00\n",
      "obtained google trends for the period 2018-06-09T00 2018-06-16T00\n",
      "obtained google trends for the period 2018-06-16T00 2018-06-23T00\n",
      "obtained google trends for the period 2018-06-23T00 2018-06-30T00\n",
      "obtained google trends for the period 2018-06-30T00 2018-07-07T00\n",
      "obtained google trends for the period 2018-07-07T00 2018-07-14T00\n",
      "obtained google trends for the period 2018-07-14T00 2018-07-21T00\n",
      "obtained google trends for the period 2018-07-21T00 2018-07-28T00\n",
      "obtained google trends for the period 2018-07-28T00 2018-08-04T00\n",
      "obtained google trends for the period 2018-08-04T00 2018-08-11T00\n",
      "obtained google trends for the period 2018-08-11T00 2018-08-18T00\n",
      "obtained google trends for the period 2018-08-18T00 2018-08-25T00\n",
      "obtained google trends for the period 2018-08-25T00 2018-09-01T00\n",
      "obtained google trends for the period 2018-09-01T00 2018-09-08T00\n",
      "obtained google trends for the period 2018-09-08T00 2018-09-15T00\n",
      "obtained google trends for the period 2018-09-15T00 2018-09-22T00\n",
      "obtained google trends for the period 2018-09-22T00 2018-09-29T00\n",
      "obtained google trends for the period 2018-09-29T00 2018-10-06T00\n",
      "obtained google trends for the period 2018-10-06T00 2018-10-13T00\n",
      "obtained google trends for the period 2018-10-13T00 2018-10-20T00\n",
      "obtained google trends for the period 2018-10-20T00 2018-10-27T00\n",
      "obtained google trends for the period 2018-10-27T00 2018-11-03T00\n",
      "obtained google trends for the period 2018-11-03T00 2018-11-10T00\n",
      "obtained google trends for the period 2018-11-10T00 2018-11-17T00\n",
      "obtained google trends for the period 2018-11-17T00 2018-11-24T00\n",
      "obtained google trends for the period 2018-11-24T00 2018-12-01T00\n",
      "obtained google trends for the period 2018-12-01T00 2018-12-08T00\n",
      "obtained google trends for the period 2018-12-08T00 2018-12-15T00\n",
      "obtained google trends for the period 2018-12-15T00 2018-12-22T00\n",
      "obtained google trends for the period 2018-12-22T00 2018-12-29T00\n",
      "obtained google trends for the period 2018-12-29T00 2019-01-05T00\n",
      "obtained google trends for the period 2019-01-05T00 2019-01-12T00\n",
      "obtained google trends for the period 2019-01-12T00 2019-01-19T00\n",
      "obtained google trends for the period 2019-01-19T00 2019-01-26T00\n",
      "obtained google trends for the period 2019-01-26T00 2019-02-02T00\n",
      "obtained google trends for the period 2019-02-02T00 2019-02-09T00\n",
      "obtained google trends for the period 2019-02-09T00 2019-02-16T00\n",
      "obtained google trends for the period 2019-02-16T00 2019-02-23T00\n",
      "obtained google trends for the period 2019-02-23T00 2019-03-02T00\n",
      "obtained google trends for the period 2019-03-02T00 2019-03-09T00\n",
      "obtained google trends for the period 2019-03-09T00 2019-03-16T00\n",
      "obtained google trends for the period 2019-03-16T00 2019-03-23T00\n",
      "obtained google trends for the period 2019-03-23T00 2019-03-30T00\n",
      "obtained google trends for the period 2019-03-30T00 2019-04-06T00\n",
      "obtained google trends for the period 2019-04-06T00 2019-04-13T00\n",
      "obtained google trends for the period 2019-04-13T00 2019-04-20T00\n",
      "obtained google trends for the period 2019-04-20T00 2019-04-27T00\n",
      "obtained google trends for the period 2019-04-27T00 2019-05-04T00\n",
      "obtained google trends for the period 2019-05-04T00 2019-05-11T00\n",
      "obtained google trends for the period 2019-05-11T00 2019-05-18T00\n"
     ]
    }
   ],
   "source": [
    "dfs0={}\n",
    "for i in dates0:\n",
    "    dfs0[i]={}\n",
    "    for j in dates0[i]: #each week in the year\n",
    "        if type(j) == float and math.isnan(j):\n",
    "            continue\n",
    "        endpoints = j.split(\" \")\n",
    "        key = endpoints[0] + \"T00 \" + endpoints[1] + \"T00\"\n",
    "        time.sleep(random.randint(0,2))\n",
    "        p=TrendReq()\n",
    "        p.build_payload(keyword_list,timeframe=key)\n",
    "        dfs0[i][j]=p.interest_over_time()\n",
    "        print(\"obtained google trends for the period {}\".format(key))\n",
    "#saving the first 98 weeks trend scores in a dictionary(file)\n",
    "np.save('dfs0.npy', dfs0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obtained Gtrends for the period 2019-05-18T00 2019-05-25T00\n",
      "obtained Gtrends for the period 2019-05-25T00 2019-06-01T00\n",
      "obtained Gtrends for the period 2019-06-01T00 2019-06-08T00\n",
      "obtained Gtrends for the period 2019-06-08T00 2019-06-15T00\n",
      "obtained Gtrends for the period 2019-06-15T00 2019-06-21T00\n"
     ]
    }
   ],
   "source": [
    "dfs1={}\n",
    "for i in dates1:\n",
    "    dfs1[i]={}\n",
    "    for j in dates1[i]: #each week in the year\n",
    "        if type(j) == float and math.isnan(j):\n",
    "            continue\n",
    "        endpoints = j.split(\" \")\n",
    "        key = endpoints[0] + \"T00 \" + endpoints[1] + \"T00\"\n",
    "        time.sleep(2)\n",
    "        p=TrendReq()\n",
    "        p.build_payload(keyword_list,timeframe=key)\n",
    "        dfs1[i][j]=p.interest_over_time()\n",
    "        print(\"obtained Gtrends for the period {}\".format(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving other weeks trend scores in other dictionary\n",
    "np.save('dfs1.npy', dfs1) \n",
    "##What Google give us is the percentage of how much the keyword has been searched, calculated over that week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading and Merging both dicts.\n",
    "dfs0=np.load('dfs0.npy').item()\n",
    "dfs1=np.load('dfs1.npy').item()\n",
    "dfs={}\n",
    "dfs.update(dfs0)\n",
    "dfs[\"Weeks\"].update(dfs1[\"Weeks\"])\n",
    "len(dfs[\"Weeks\"])==len(dates0)+len(dates1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bitcoin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-06-20 20:00:00</th>\n",
       "      <td>7.514694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-20 21:00:00</th>\n",
       "      <td>7.436416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-20 22:00:00</th>\n",
       "      <td>7.749528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-20 23:00:00</th>\n",
       "      <td>6.731913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-21 00:00:00</th>\n",
       "      <td>6.262245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      bitcoin\n",
       "date                         \n",
       "2019-06-20 20:00:00  7.514694\n",
       "2019-06-20 21:00:00  7.436416\n",
       "2019-06-20 22:00:00  7.749528\n",
       "2019-06-20 23:00:00  6.731913\n",
       "2019-06-21 00:00:00  6.262245"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so we have to \"standarize\" all weeks by Stitching  together the timeseries: \n",
    "#we can calculate the scaling ratio between two different intervals with its last score and the first of the next interval,\n",
    "#and then scale one of those intervals to match the other.\n",
    "keyword=keyword_list#=\"bitcoin\"\n",
    "dates=pd.concat([dates0,dates1]) #joining the dates DFs\n",
    "timeseries=pd.DataFrame(dfs[\"Weeks\"][\"2017-07-01 2017-07-08\"]) # the initial timeseries as DF\n",
    "for i in dates:\n",
    "    for j in dates[i]:\n",
    "        if type(j) == float and math.isnan(j):\n",
    "            continue\n",
    "        if j != \"2017-07-01 2017-07-08\":\n",
    "            df1 = timeseries\n",
    "            df2 = dfs[i][j]\n",
    "            ratio = float(df2[keyword].iloc[0])/float(df1[keyword].iloc[-1]) \n",
    "            df1[keyword]=ratio*df1[keyword]\n",
    "            timeseries = pd.concat([timeseries,df2])\n",
    "m=np.max(timeseries[keyword])\n",
    "timeseries[keyword]=100*timeseries[keyword]/m\n",
    "del timeseries['isPartial']\n",
    "timeseries.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the final timeseries with the standarized Gtrends to Excel file\n",
    "timeseries.to_excel(\"bitcoingtrends.xlsx\",sheet_name='Gtrends')\n",
    "print(\"file generated: bitcoingtrends.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
